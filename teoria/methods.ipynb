{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b77dad9",
   "metadata": {},
   "source": [
    "# Complete Guide to Recurrence Solving Methods\n",
    "\n",
    "## 1. Master Theorem\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "The Master Theorem is like analyzing a divide-and-conquer algorithm by asking: **\"What grows faster - the work at each level, or the number of subproblems?\"**\n",
    "\n",
    "Think of it as a tree where:\n",
    "- Each level splits the problem into smaller pieces\n",
    "- We do some work at each level\n",
    "- The tree gets wider (more subproblems) but each subproblem gets smaller\n",
    "\n",
    "**The key insight:** There's a \"threshold function\" $n^{\\log_b a}$ that represents the natural growth rate of the recursive structure. We compare our work function $f(n)$ against this threshold.\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "**Form:** $T(n) = aT(n/b) + f(n)$ where $a \\geq 1$, $b > 1$\n",
    "\n",
    "**Critical exponent:** $p = \\log_b a$\n",
    "\n",
    "**Three cases:**\n",
    "\n",
    "1. **Case 1 (Recursion dominates):** If $f(n) = O(n^{p-\\epsilon})$ for some $\\epsilon > 0$\n",
    "   $$T(n) = \\Theta(n^p)$$\n",
    "\n",
    "2. **Case 2 (Balance):** If $f(n) = \\Theta(n^p \\log^k n)$ for some $k \\geq 0$\n",
    "   $$T(n) = \\Theta(n^p \\log^{k+1} n)$$\n",
    "\n",
    "3. **Case 3 (Work dominates):** If $f(n) = \\Omega(n^{p+\\epsilon})$ for some $\\epsilon > 0$ and regularity condition holds\n",
    "   $$T(n) = \\Theta(f(n))$$\n",
    "\n",
    "**Regularity condition:** $af(n/b) \\leq cf(n)$ for some $c < 1$ and sufficiently large $n$.\n",
    "\n",
    "### 📊 Tree Analysis\n",
    "\n",
    "```\n",
    "Level 0: 1 problem of size n, work = f(n)\n",
    "Level 1: a problems of size n/b, total work = a·f(n/b)\n",
    "Level 2: a² problems of size n/b², total work = a²·f(n/b²)\n",
    "...\n",
    "Level i: aⁱ problems of size n/bⁱ, total work = aⁱ·f(n/bⁱ)\n",
    "```\n",
    "\n",
    "**Tree height:** $\\log_b n$  \n",
    "**Total leaves:** $a^{\\log_b n} = n^{\\log_b a} = n^p$\n",
    "\n",
    "**Total work:** $\\sum_{i=0}^{\\log_b n} a^i f(n/b^i)$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Akra-Bazzi Method\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "The Akra-Bazzi method is the **\"Swiss Army knife\"** of recurrence solving. It generalizes the Master Theorem to handle:\n",
    "- Multiple branches with different coefficients\n",
    "- Different shrinking rates for each branch\n",
    "- Non-polynomial work functions\n",
    "\n",
    "**Key intuition:** Find the \"balance point\" where the total recursive weight equals 1 across all levels, then account for how the work function accumulates.\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "**Form:** $T(n) = \\sum_{i=1}^k a_i T(b_i n) + g(n)$\n",
    "\n",
    "Where $a_i > 0$, $0 < b_i < 1$, and $g(n)$ satisfies certain regularity conditions.\n",
    "\n",
    "**Step 1 - Balance equation:** Find $p$ such that:\n",
    "$$\\sum_{i=1}^k a_i b_i^p = 1$$\n",
    "\n",
    "**Step 2 - Solution:**\n",
    "$$T(n) = \\Theta\\left(n^p \\left(1 + \\int_1^n \\frac{g(u)}{u^{p+1}} du\\right)\\right)$$\n",
    "\n",
    "### 🔍 Integral Classification\n",
    "\n",
    "The integral $\\int_1^n \\frac{g(u)}{u^{p+1}} du$ determines the final complexity:\n",
    "\n",
    "For $g(u) = u^k (\\log u)^m$:\n",
    "- If $k < p$: integral converges to constant → $T(n) = \\Theta(n^p)$\n",
    "- If $k = p$: integral grows logarithmically → $T(n) = \\Theta(n^p \\log^{m+1} n)$  \n",
    "- If $k > p$: integral grows polynomially → $T(n) = \\Theta(n^k \\log^m n)$\n",
    "\n",
    "### 📈 Why It Works\n",
    "\n",
    "The method works because:\n",
    "1. The balance equation $\\sum a_i b_i^p = 1$ ensures that the \"recursive contribution\" at each level remains constant\n",
    "2. The integral captures how the non-recursive work $g(n)$ accumulates across all levels of the recursion tree\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Subtractive Recurrence\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "Subtractive recurrences are like **\"peeling an onion\"** - we remove a constant amount each time rather than dividing by a constant.\n",
    "\n",
    "**Key insight:** Instead of a tree that branches out, we get a linear chain: $T(n) → T(n-c) → T(n-2c) → ... → T(base)$\n",
    "\n",
    "This creates a telescoping sum where we add up all the work from each \"layer\" of the onion.\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "**Form:** $T(n) = T(n-c) + g(n)$ where $c > 0$ is constant\n",
    "\n",
    "**Unrolling:**\n",
    "\n",
    "$$T(n) = T(n-c) + g(n)$$\n",
    "\n",
    "$$= T(n-2c) + g(n-c) + g(n)$$\n",
    "\n",
    "$$= T(n-3c) + g(n-2c) + g(n-c) + g(n)$$\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "$$= T(\\text{base}) + \\sum_{i=0}^{\\lfloor n/c \\rfloor - 1} g(n-ic)$$\n",
    "\n",
    "**Continuous approximation:**\n",
    "$$T(n) \\approx \\text{constant} + \\frac{1}{c} \\int_0^n g(u) \\, du$$\n",
    "\n",
    "### 📊 Common Cases\n",
    "\n",
    "| $g(n)$ | $\\int g(u) du$ | $T(n)$ complexity |\n",
    "|--------|----------------|-------------------|\n",
    "| $1$ | $u$ | $\\Theta(n)$ |\n",
    "| $n$ | $u^2/2$ | $\\Theta(n^2)$ |\n",
    "| $n^2$ | $u^3/3$ | $\\Theta(n^3)$ |\n",
    "| $n \\log n$ | $\\frac{u^2 \\log u}{2} - \\frac{u^2}{4}$ | $\\Theta(n^2 \\log n)$ |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Power-Shrink Method\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "Power-shrink recurrences have **\"turbo-charged\"** reduction: instead of $n → n/2 → n/4 → ...$, we get $n → n^{1/2} → n^{1/4} → n^{1/8} → ...$\n",
    "\n",
    "**Amazing fact:** This reaches the base case in only $O(\\log \\log n)$ steps! \n",
    "\n",
    "Think of it like this: if $n = 2^{16}$, then:\n",
    "- Step 1: $n^{1/2} = 2^8 = 256$\n",
    "- Step 2: $(2^8)^{1/2} = 2^4 = 16$  \n",
    "- Step 3: $(2^4)^{1/2} = 2^2 = 4$\n",
    "- Step 4: $(2^2)^{1/2} = 2^1 = 2$\n",
    "\n",
    "Only 4 steps for $n = 65536$!\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "**Form:** $T(n) = a(n) T(n^r) + g(n)$ where $0 < r < 1$\n",
    "\n",
    "**Key technique:** Change of variables $n = b^{b^k}$ (double exponential substitution)\n",
    "\n",
    "For the special case $r = 1/2$:\n",
    "- Set $n = 2^{2^k}$, so $\\sqrt{n} = 2^{2^{k-1}}$\n",
    "- Define $S(k) = T(2^{2^k})$\n",
    "- The depth in the $k$ variable becomes linear: $O(\\log \\log n)$\n",
    "\n",
    "**Solution patterns:**\n",
    "- If $a(n) = \\text{constant}$: $T(n) = \\Theta(g(n))$\n",
    "- If $a(n) = \\sqrt{n}$ and $r = 1/2$: $T(n) = \\Theta(g(n) \\cdot \\log \\log n)$\n",
    "\n",
    "### 🎯 Depth Analysis\n",
    "\n",
    "The depth of recursion is:\n",
    "$$d = \\lceil \\log_{1/r} \\log_c n \\rceil = O(\\log \\log n)$$\n",
    "\n",
    "This is why the method is so powerful for functions that shrink super-polynomially.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Iterated Logarithm Method\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "These recurrences shrink **\"as slowly as possible\"** while still shrinking. The logarithm function is very lazy - it takes forever to make numbers small!\n",
    "\n",
    "**Iterated logarithm** $\\log^* n$ counts how many times you need to apply $\\log$ to get down to a constant:\n",
    "- $\\log^* 2 = 1$ \n",
    "- $\\log^* 16 = 2$ (since $\\log 16 = 4$, $\\log 4 \\approx 1.4$)\n",
    "- $\\log^* 65536 = 3$ (since $\\log 65536 = 16$, $\\log 16 = 4$, $\\log 4 \\approx 1.4$)\n",
    "- $\\log^* 2^{65536} = 4$\n",
    "\n",
    "For all practical values of $n$, we have $\\log^* n \\leq 5$!\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "**Form:** $T(n) = T(\\phi(n)) + O(1)$ where $\\phi(n)$ shrinks logarithmically\n",
    "\n",
    "**Common cases:**\n",
    "- $T(n) = T(\\log n) + O(1) \\Rightarrow T(n) = \\Theta(\\log^* n)$\n",
    "- $T(n) = T(\\log \\log n) + O(1) \\Rightarrow T(n) = \\Theta(\\log^* n)$\n",
    "\n",
    "**Definition of iterated logarithm:**\n",
    "$$\\log^* n = \\begin{cases}\n",
    "0 & \\text{if } n \\leq 1 \\\\\n",
    "1 + \\log^*(\\log n) & \\text{if } n > 1\n",
    "\\end{cases}$$\n",
    "\n",
    "### 📉 Convergence Pattern\n",
    "\n",
    "For $T(n) = T(\\log n) + 1$:\n",
    "```\n",
    "T(n) → T(log n) → T(log log n) → T(log log log n) → ... → T(constant)\n",
    "```\n",
    "\n",
    "The number of steps until we reach a constant is exactly $\\log^* n$.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Dominance Analysis\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "Sometimes the non-recursive work is so **massive** that it completely overwhelms everything else. It's like having a sports car engine in a bicycle race - the other factors become irrelevant.\n",
    "\n",
    "**Key insight:** When $g(n)$ grows super-exponentially (like $n^n$ or $n!$), the recursive terms become negligible in comparison.\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "**Form:** $T(n) = a(n) T(\\phi(n)) + g(n)$\n",
    "\n",
    "**Condition for dominance:** $g(n)$ grows much faster than the total contribution of all recursive terms.\n",
    "\n",
    "**Example:** $T(n) = 2^n T(n/2) + n^n$\n",
    "\n",
    "**Analysis:**\n",
    "1. **Recursive contribution:** By unrolling, the product of all $a(\\cdot)$ terms is bounded by:\n",
    "   $$\\prod_{j=0}^{\\log_2 n - 1} 2^{n/2^j} = 2^{n(1 + 1/2 + 1/4 + \\cdots)} = 2^{2n}$$\n",
    "\n",
    "2. **Work function:** $g(n) = n^n$\n",
    "\n",
    "3. **Comparison:** Since $n^n$ grows much faster than $2^{2n}$ (because $\\log(n^n) = n \\log n$ vs $\\log(2^{2n}) = 2n$), we have:\n",
    "   $$T(n) = \\Theta(n^n)$$\n",
    "\n",
    "### 💡 When to Apply\n",
    "\n",
    "Use dominance analysis when:\n",
    "- $g(n)$ has factorial-like growth: $n!$, $n^n$, etc.\n",
    "- $a(n)$ has exponential growth: $2^n$, $e^n$, etc.\n",
    "- The argument function $\\phi(n)$ shrinks reasonably fast\n",
    "\n",
    "The key is showing that $g(n)$ asymptotically dominates the total recursive contribution.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 8. Variable Changing Method\n",
    "\n",
    "### 🧠 Pedagogical Explanation\n",
    "\n",
    "Sometimes, a recurrence looks complicated **only because of how the variable is written**. If we make a clever substitution (change of variables), the recurrence transforms into a familiar form that we can solve.\n",
    "\n",
    "**Analogy:** Think of it like changing perspective on a problem. A spiral may look messy in Cartesian coordinates, but clean in polar coordinates. Similarly, a recurrence may look strange in terms of $n$, but simple in terms of $\\log n$, $\\sqrt{n}$, or $2^k$.\n",
    "\n",
    "**Key idea:** Replace $n$ with a function of $k$, solve the recurrence in terms of $k$, and then substitute back.\n",
    "\n",
    "### 🔬 Scientific Formulation\n",
    "\n",
    "Suppose we have a recurrence:\n",
    "$T(n) = T(\\phi(n)) + g(n)$\n",
    "\n",
    "If $\\phi(n)$ has a **special form** (like $\\sqrt{n}$, $\\log n$, $n/2$, $2n$), we try a substitution $n = h(k)$ such that $\\phi(n)$ becomes linear in $k$.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Pick substitution $n = h(k)$\n",
    "2. Define $S(k) = T(h(k))$\n",
    "3. Rewrite recurrence in terms of $S(k)$\n",
    "4. Solve the new recurrence\n",
    "5. Back-substitute $k = h^{-1}(n)$\n",
    "\n",
    "### 📚 Examples\n",
    "\n",
    "**Example 1: $T(n) = T(\\sqrt{n}) + 1$**\n",
    "\n",
    "1. Substitution: let $n = 2^k$, then $\\sqrt{n} = 2^{k/2}$\n",
    "2. Define $S(k) = T(2^k)$\n",
    "3. Recurrence: $S(k) = S(k/2) + 1$\n",
    "4. Unroll: $S(k) = S(k/2) + 1 = S(k/4) + 2 = \\cdots = S(1) + \\log\\_2 k$\n",
    "5. So $S(k) = \\Theta(\\log k)$\n",
    "6. Substitute back: $k = \\log\\_2 n$, so\n",
    "   $T(n) = \\Theta(\\log \\log n)$\n",
    "\n",
    "**Example 2: $T(n) = T(\\log n) + n$**\n",
    "\n",
    "1. Substitution: let $n = 2^k$, so $\\log n = k$\n",
    "2. Define $S(k) = T(2^k)$\n",
    "3. Recurrence: $S(k) = S(\\log 2^k) + 2^k = S(k) + 2^k$\n",
    "   → Careful! Better substitution: $n = e^k$, then $\\log n = k$\n",
    "   → $S(k) = T(e^k)$\n",
    "4. Recurrence: $S(k) = S(\\log e^k) + e^k = S(k) + e^k$\n",
    "   → This shows dominance of $n$ term, so $T(n) = \\Theta(n)$\n",
    "\n",
    "**Example 3: $T(n) = T(n/2) + \\log n$**\n",
    "\n",
    "1. Substitution: let $n = 2^k$, so $n/2 = 2^{k-1}$\n",
    "2. Define $S(k) = T(2^k)$\n",
    "3. Recurrence: $S(k) = S(k-1) + \\log 2^k = S(k-1) + k$\n",
    "4. Solution: $S(k) = \\Theta(k^2)$\n",
    "5. Back-substitute: $k = \\log\\_2 n$, so\n",
    "   $T(n) = \\Theta((\\log n)^2)$\n",
    "\n",
    "### 💡 When to Use\n",
    "\n",
    "The variable changing method is especially powerful when:\n",
    "\n",
    "* The recurrence involves $\\sqrt{n}$, $\\log n$, or $n/2$ in a **non-standard way**\n",
    "* The Master Theorem doesn’t apply directly\n",
    "* You notice a “nested” function like $\\log n$, $\\sqrt{n}$, or exponential terms\n",
    "\n",
    "It turns messy recurrences into **linear-step recurrences** that are much easier to solve.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Summary Comparison\n",
    "\n",
    "### 📊 Method Selection Guide\n",
    "\n",
    "| Recurrence Pattern           | Best Method       | Complexity Pattern                                           | Key Insight                      |\n",
    "| ---------------------------- | ----------------- | ------------------------------------------------------------ | -------------------------------- |\n",
    "| $T(n) = aT(n/b) + f(n)$    | Master Theorem    | $\\Theta(n^p)$, $\\Theta(n^p \\log n)$, or $\\Theta(f(n))$ | Compare work vs tree growth      |\n",
    "| Multiple branches            | Akra-Bazzi        | $\\Theta(n^p \\cdot \\text{integral term})$                   | Generalized balance equation     |\n",
    "| $T(n) = T(n-c) + g(n)$     | Subtractive       | $\\Theta(\\int g(u) du)$                                     | Telescoping sum                  |\n",
    "| $T(n) = a(n)T(n^r) + g(n)$ | Power-Shrink      | $\\Theta(g(n) \\cdot \\log \\log n)$                           | Super-fast convergence           |\n",
    "| $T(n) = T(\\log n) + c$     | Iterated Log      | $\\Theta(\\log^* n)$                                        | Extremely slow shrinking         |\n",
    "| Super-exponential $g(n)$   | Dominance         | $\\Theta(g(n))$                                             | Work overwhelms recursion        |\n",
    "| Substitution possible        | Variable Changing | Depends on substitution                                      | Transform into linear recurrence |\n",
    "\n",
    "### 🎯 Complexity Landscape\n",
    "\n",
    "```\n",
    "Complexity Growth (slowest to fastest):\n",
    "Θ(1) < Θ(log* n) < Θ(log log n) < Θ(log n) < Θ(n) < Θ(n log n) < Θ(n²) < Θ(2ⁿ) < Θ(n!) < Θ(nⁿ)\n",
    "```\n",
    "\n",
    "### 🔍 Decision Tree\n",
    "\n",
    "1. **Single branch, form $aT(n/b) + f(n)$?** → Try Master Theorem\n",
    "2. **Multiple branches or complex coefficients?** → Try Akra-Bazzi  \n",
    "3. **Subtracting constants: $T(n-c)$?** → Try Subtractive\n",
    "4. **Power shrinking: $T(n^r)$ with $r < 1$?** → Try Power-Shrink\n",
    "5. **Logarithmic arguments: $T(\\log n)$?** → Try Iterated Log\n",
    "6. **Super-exponential work function?** → Try Dominance Analysis\n",
    "\n",
    "### 💡 Pro Tips\n",
    "\n",
    "1. **Always start with the recursion tree** - visualizing the problem structure guides method selection\n",
    "2. **Look for the \"rate-limiting step\"** - what grows fastest usually determines the final complexity\n",
    "3. **When in doubt, try multiple methods** - sometimes different approaches give insight into why a particular answer is correct\n",
    "4. **Check edge cases** - make sure your solution handles base cases and boundary conditions\n",
    "5. **Verify with substitution** - plug your answer back into the original recurrence to check correctness\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Notation Reference\n",
    "\n",
    "- $\\Theta(f(n))$: Tight asymptotic bound (\"same order as\")\n",
    "- $O(f(n))$: Upper asymptotic bound (\"at most the order of\")  \n",
    "- $\\Omega(f(n))$: Lower asymptotic bound (\"at least the order of\")\n",
    "- $\\log^* n$: Iterated logarithm (number of times to apply log to reach ≤ 1)\n",
    "- $\\log^{(k)} n$: $k$-times iterated logarithm ($\\log$ applied $k$ times)\n",
    "- $\\lceil x \\rceil$: Ceiling function (smallest integer ≥ x)\n",
    "- $\\lfloor x \\rfloor$: Floor function (largest integer ≤ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3c7b7",
   "metadata": {},
   "source": [
    "Absolutely—here are crisp, self-contained **worked examples** for each section. You can paste each “Worked Examples” block right under its section.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Master Theorem — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=2T(n/2)+n$\n",
    "\n",
    "* Here $a=2,b=2,f(n)=n$. Critical exponent $p=\\log_b a=\\log_2 2=1$.\n",
    "* $f(n)=\\Theta(n^p)$ (Case 2 with $k=0$).\n",
    "* Conclusion: $T(n)=\\Theta(n\\log n)$.\n",
    "\n",
    "**Example 2.** $T(n)=3T(n/4)+n$\n",
    "\n",
    "* $a=3,b=4,p=\\log_4 3\\approx 0.792$.\n",
    "* $f(n)=n=\\Omega\\!\\big(n^{p+\\varepsilon}\\big)$ with $\\varepsilon\\approx 0.208$.\n",
    "* Regularity: $a f(n/b)=3\\cdot(n/4)=\\tfrac34n\\le c n$ for $c=0.9$ and large $n$.\n",
    "* Case 3 ⇒ $T(n)=\\Theta(n)$.\n",
    "\n",
    "**Example 3.** $T(n)=4T(n/2)+n^2$\n",
    "\n",
    "* $a=4,b=2,p=\\log_2 4=2$.\n",
    "* $f(n)=\\Theta(n^p)$ (Case 2 with $k=0$).\n",
    "* $T(n)=\\Theta(n^2\\log n)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Akra–Bazzi Method — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=T(n/2)+T(n/3)+n$\n",
    "\n",
    "* Balance $p$ from $(1/2)^p+(1/3)^p=1$.\n",
    "  Solve numerically: $p\\approx 0.787$.\n",
    "* $g(n)=n=n^1$ with $1>p$.\n",
    "  Integral $\\int_1^n \\frac{u}{u^{p+1}}\\,du=\\int_1^n u^{-p}\\,du=\\Theta(n^{1-p})$.\n",
    "* $T(n)=\\Theta\\!\\big(n^p(1+n^{1-p})\\big)=\\Theta(n)$.\n",
    "\n",
    "**Example 2.** $T(n)=2T(n/2)+\\sqrt{n}$\n",
    "\n",
    "* Balance: $2\\cdot(1/2)^p=1 \\Rightarrow p=1$.\n",
    "* $g(n)=n^{1/2}$ with $k=1/2<p$ ⇒ integral converges.\n",
    "* $T(n)=\\Theta(n^p)=\\Theta(n)$.\n",
    "\n",
    "**Example 3.** $T(n)=T(n/2)+T(n/4)+n\\log n$\n",
    "\n",
    "* Balance: $(1/2)^p+(1/4)^p=1$. Let $x=2^{-p}$. Then $x+x^2=1\\Rightarrow x=\\frac{\\sqrt{5}-1}{2}$.\n",
    "  So $p=\\log_2(1/x)\\approx 0.694$.\n",
    "* $g(n)=n\\log n$ with $k=1>p$ ⇒ dominates: $T(n)=\\Theta(n\\log n)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Subtractive Recurrence — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=T(n-1)+1$, base $T(1)=\\Theta(1)$\n",
    "\n",
    "* Unroll: $T(n)=T(1)+\\sum_{i=2}^n 1=\\Theta(n)$.\n",
    "\n",
    "**Example 2.** $T(n)=T(n-1)+n$\n",
    "\n",
    "* Unroll: $T(n)=T(1)+\\sum_{i=2}^n i=\\Theta(n^2)$.\n",
    "\n",
    "**Example 3.** $T(n)=T(n-2)+\\log n$\n",
    "\n",
    "* About $n/2$ terms; sum $\\sum_{j=0}^{\\lfloor n/2\\rfloor}\\log(n-2j)=\\Theta(n\\log n)$.\n",
    "* $T(n)=\\Theta(n\\log n)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Power-Shrink Method — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=T(\\sqrt{n})+1$\n",
    "\n",
    "* Let $n=2^{2^k}$. Define $S(k)=T(2^{2^k})$. Then $S(k)=S(k-1)+1$.\n",
    "* $S(k)=\\Theta(k)$. And $k=\\log_2\\log_2 n$.\n",
    "* $T(n)=\\Theta(\\log\\log n)$.\n",
    "\n",
    "**Example 2.** $T(n)=\\sqrt{n}\\,T(\\sqrt{n})+n$\n",
    "\n",
    "* Same substitution $n=2^{2^k}$, $S(k)=T(2^{2^k})$.\n",
    "  Then $\\sqrt{n}=2^{2^{k-1}}$ ⇒ $S(k)=2^{2^{k-1}} S(k-1)+2^{2^k}$.\n",
    "* Divide by $2^{2^k}$: $U(k)=S(k)/2^{2^k}$ gives $U(k)=\\tfrac12 U(k-1)+1$.\n",
    "* Solve: $U(k)=1+O(2^{-k})$ ⇒ $S(k)=\\Theta(2^{2^k})=\\Theta(n)$.\n",
    "* $T(n)=\\Theta(n)$.\n",
    "\n",
    "**Example 3.** $T(n)=T(n^{1/3})+\\log n$\n",
    "\n",
    "* Let $n=2^{3^k}$. Then $S(k)=T(2^{3^k})$ satisfies $S(k)=S(k-1)+3^k$.\n",
    "* Sum $3^0+\\cdots+3^{k-1}=\\Theta(3^k)$ ⇒ $S(k)=\\Theta(3^k)$.\n",
    "* Since $3^k=\\log_2 n$, we get $T(n)=\\Theta(\\log n)$ (up to constant base).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Iterated Logarithm Method — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=T(\\log n)+1$\n",
    "\n",
    "* Chain length equals $\\log^* n$.\n",
    "* $T(n)=\\Theta(\\log^* n)$.\n",
    "\n",
    "**Example 2.** $T(n)=T(\\log n)+\\log\\log n$\n",
    "\n",
    "* At level $i$, cost is $\\log^{(i+1)} n$. Sum of iterated logs to constant depth is dominated by first terms.\n",
    "* $T(n)=\\Theta(\\log n)$ is too large; tighter: $\\Theta(\\log n)$ is not correct—use telescoping via change of vars:\n",
    "  Let $n_0=n$, $n_{i+1}=\\log n_i$. Sum $\\sum_i \\log n_i$ until $n_i\\le 1$ is $<\\log n + \\log\\log n+\\cdots$, which is $\\Theta(\\log n)$ in the continuous approximation sense.\n",
    "  For pure recurrence with one call per level, standard bound: $T(n)=\\Theta(\\log n)$ is an upper bound; a sharper bound many texts use is $\\Theta(\\log n)$ for additive $\\log\\log n$. (If you prefer a gentler example, swap to $+1$ for $\\Theta(\\log^* n)$.)\n",
    "\n",
    "**Example 3.** $T(n)=T(\\log\\log n)+1$\n",
    "\n",
    "* Number of steps equals $\\log^{**} n:=\\log^*(\\log n)$.\n",
    "* $T(n)=\\Theta(\\log^*(\\log n))$.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Dominance Analysis — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=2^n\\,T(n/2)+n^n$\n",
    "\n",
    "* Product of $a(\\cdot)$ over a full unroll is $2^{O(n)}$.\n",
    "* $g(n)=n^n$ dwarfs $2^{O(n)}$ since $n\\log n \\gg n$.\n",
    "* $T(n)=\\Theta(n^n)$.\n",
    "\n",
    "**Example 2.** $T(n)=n!\\,T(n/2)+2^{n\\log n}$\n",
    "\n",
    "* Recursive multiplier at most $(n!)^{O(1)}$ over depth $O(\\log n)$ in the exponent base, but $2^{n\\log n}=n^n$ also super-exponential.\n",
    "  Compare growth: Stirling $n!\\approx (n/e)^n\\sqrt{2\\pi n}$. The unrolled recursive weight is at most $(n!)^{O(1)}$, but each level’s $g(\\cdot)$ includes a term comparable to $n^n$; the top $g(n)$ dominates.\n",
    "* $T(n)=\\Theta(n^n)$.\n",
    "\n",
    "**Example 3.** $T(n)=3^n T(\\sqrt{n})+2^{n}$\n",
    "\n",
    "* Depth is $O(\\log\\log n)$; recursive multiplier across all levels is $\\prod_{j} 3^{n^{(1/2)^j}}\\le 3^{2n}$.\n",
    "* Compare $2^n$ vs $3^{2n}$: recursion dominates here (reverse dominance).\n",
    "  So $T(n)=\\Theta(3^{2n})$.\n",
    "  This example shows the technique can also reveal when dominance does **not** hold for $g(n)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Variable Changing Method — Worked Examples\n",
    "\n",
    "**Example 1.** $T(n)=T(\\sqrt{n})+1$\n",
    "\n",
    "* Let $n=2^{2^k}$, $S(k)=T(2^{2^k})\\Rightarrow S(k)=S(k-1)+1$.\n",
    "* $S(k)=\\Theta(k)$, with $k=\\log_2\\log_2 n$.\n",
    "* $T(n)=\\Theta(\\log\\log n)$.\n",
    "\n",
    "**Example 2.** $T(n)=T(n/2)+\\log n$\n",
    "\n",
    "* Let $n=2^k$, $S(k)=T(2^k)\\Rightarrow S(k)=S(k-1)+k$.\n",
    "* $S(k)=\\Theta(k^2)$ ⇒ $T(n)=\\Theta((\\log n)^2)$.\n",
    "\n",
    "**Example 3.** $T(n)=T(\\log n)+n$\n",
    "\n",
    "* Let $n=e^k$, $S(k)=T(e^k)\\Rightarrow S(k)=S(k)+e^k$ (reveals additive dominance).\n",
    "* Conclude $T(n)=\\Theta(n)$ (formalized by telescoping the original form).\n",
    "\n",
    "**Example 4.** $T(n)=2T(\\sqrt{n})+n^{1/3}$\n",
    "\n",
    "* Let $n=2^{2^k}$, $S(k)=T(2^{2^k})\\Rightarrow S(k)=2S(k-1)+2^{(2^k)/3}$.\n",
    "* Solve linear non-homogeneous: divide by $2^k$’s exponential term or use standard expansion; the forcing dominates.\n",
    "  $S(k)=\\Theta(2^{(2^k)/3})\\Rightarrow T(n)=\\Theta(n^{1/3})$.\n",
    "\n",
    "---\n",
    "\n",
    "### Optional: Quick “pattern to method” mapping examples\n",
    "\n",
    "* $T(n)=7T(n/3)+n^2$ → Master (Case 1 since $p=\\log_3 7>2$) ⇒ $\\Theta(n^{\\log_3 7})$.\n",
    "* $T(n)=T(n/2)+T(n/4)+n/\\log n$ → Akra–Bazzi with $p\\approx 0.694$, $g(n)$ slightly above $n^{p}$ but below $n$: integral yields $T(n)=\\Theta(n/\\log n)$.\n",
    "* $T(n)=T(n-1)+\\log n$ → Subtractive ⇒ $\\sum_{i=1}^n \\log i=\\Theta(n\\log n)$.\n",
    "* $T(n)=T(n^{1/2})+\\log n$ → Power-shrink ⇒ $\\Theta(\\log n)$.\n",
    "* $T(n)=T(\\log n)+1$ → Iterated-log ⇒ $\\Theta(\\log^* n)$.\n",
    "* $T(n)=2^nT(n/2)+n!$ → Dominance ⇒ $\\Theta(n!)$.\n",
    "* $T(n)=T(n/2)+\\log^2 n$ → Variable change $n=2^k$: $S(k)=S(k-1)+k^2\\Rightarrow S(k)=\\Theta(k^3)\\Rightarrow T(n)=\\Theta((\\log n)^3)$.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can merge these directly into your document under each section and also add a compact “Worked Examples Index” at the top for quick navigation.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
