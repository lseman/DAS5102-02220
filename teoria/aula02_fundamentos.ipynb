{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df10111",
   "metadata": {},
   "source": [
    "# Complexity Analysis\n",
    "\n",
    "## Part 1: What Are Recurrence Relations?\n",
    "\n",
    "### Intuitive Definition\n",
    "\n",
    "A **recurrence relation** is a way to define a sequence where each term is expressed in terms of previous terms. It's like a recipe that tells you how to build the next step based on what you've already done.\n",
    "\n",
    "**Real-world analogy**: Think of climbing stairs\n",
    "- To get to step $n$, you can either:\n",
    "  - Come from step $n-1$ and take 1 step, OR\n",
    "  - Come from step $n-2$ and take 2 steps\n",
    "- This gives us: $T(n) = T(n-1) + T(n-2)$ (Fibonacci-like)\n",
    "\n",
    "### Mathematical Definition\n",
    "\n",
    "A recurrence relation expresses $T(n)$ in terms of $T(k)$ where $k < n$, plus some function of $n$.\n",
    "\n",
    "**General form**: $T(n) = f(T(n-1), T(n-2), ..., T(n-k)) + g(n)$\n",
    "\n",
    "**Base case(s)**: Values for small $n$ (like $T(0)$, $T(1)$) that stop the recursion.\n",
    "\n",
    "## Part 2: Simple Examples to Build Intuition\n",
    "\n",
    "### Example 1: Factorial\n",
    "\n",
    "**Problem**: Calculate $n! = n \\times (n-1) \\times (n-2) \\times ... \\times 1$\n",
    "\n",
    "**Recursive thinking**: $n! = n \\times (n-1)!$\n",
    "\n",
    "**Recurrence relation**:\n",
    "$$T(n) = T(n-1) + c$$\n",
    "where $c$ is the constant time to do one multiplication.\n",
    "\n",
    "**Base case**: $T(1) = c$\n",
    "\n",
    "**Let's trace it**:\n",
    "```\n",
    "T(4) = T(3) + c\n",
    "T(3) = T(2) + c  \n",
    "T(2) = T(1) + c\n",
    "T(1) = c\n",
    "```\n",
    "\n",
    "**Substituting back**:\n",
    "$$\\begin{align}\n",
    "T(4) &= T(3) + c \\\\\n",
    "&= (T(2) + c) + c \\\\\n",
    "&= ((T(1) + c) + c) + c \\\\\n",
    "&= (c + c + c) + c \\\\\n",
    "&= 4c\n",
    "\\end{align}$$\n",
    "\n",
    "**Pattern**: $T(n) = nc = O(n)$\n",
    "\n",
    "### Example 2: Sum of First n Numbers\n",
    "\n",
    "**Problem**: Calculate $1 + 2 + 3 + ... + n$\n",
    "\n",
    "**Recursive thinking**: $\\text{Sum}(n) = n + \\text{Sum}(n-1)$\n",
    "\n",
    "**Recurrence relation**:\n",
    "$$T(n) = T(n-1) + c$$\n",
    "\n",
    "**Base case**: $T(1) = c$\n",
    "\n",
    "**This is identical to factorial!** So $T(n) = O(n)$.\n",
    "\n",
    "### Example 3: Array Traversal\n",
    "\n",
    "**Problem**: Visit every element in an array of size $n$\n",
    "\n",
    "**Recursive thinking**: Process first element, then process remaining $n-1$ elements\n",
    "\n",
    "**Recurrence relation**:\n",
    "$$T(n) = T(n-1) + c$$\n",
    "\n",
    "**Base case**: $T(1) = c$\n",
    "\n",
    "**Again, same pattern**: $T(n) = O(n)$\n",
    "\n",
    "**Key insight**: Any algorithm that reduces the problem size by 1 each time will be $O(n)$.\n",
    "\n",
    "## Part 3: The Divide-and-Conquer Pattern\n",
    "\n",
    "### Example 4: Binary Search (Revisited)\n",
    "\n",
    "**Problem**: Search in a sorted array by cutting it in half repeatedly\n",
    "\n",
    "**Recursive thinking**: Compare with middle, then search half the remaining array\n",
    "\n",
    "**Recurrence relation**:\n",
    "$$T(n) = T\\left(\\frac{n}{2}\\right) + c$$\n",
    "\n",
    "**Base case**: $T(1) = c$\n",
    "\n",
    "**Let's trace it for $n = 8$**:\n",
    "```\n",
    "T(8) = T(4) + c\n",
    "T(4) = T(2) + c\n",
    "T(2) = T(1) + c  \n",
    "T(1) = c\n",
    "```\n",
    "\n",
    "**Substituting back**:\n",
    "$$\\begin{align}\n",
    "T(8) &= T(4) + c \\\\\n",
    "&= (T(2) + c) + c \\\\\n",
    "&= ((T(1) + c) + c) + c \\\\\n",
    "&= (c + c + c) + c \\\\\n",
    "&= 4c\n",
    "\\end{align}$$\n",
    "\n",
    "**How many steps**: $8 \\to 4 \\to 2 \\to 1$ is 3 cuts, plus base case = 4 total\n",
    "\n",
    "**General pattern**: $T(n) = c \\log_2(n) = O(\\log n)$\n",
    "\n",
    "### Example 5: Merge Sort\n",
    "\n",
    "**Problem**: Sort an array by dividing it in half, sorting each half, then merging\n",
    "\n",
    "**Recursive thinking**: \n",
    "1. Sort left half: $T(n/2)$\n",
    "2. Sort right half: $T(n/2)$  \n",
    "3. Merge the halves: $O(n)$\n",
    "\n",
    "**Recurrence relation**:\n",
    "$$T(n) = 2T\\left(\\frac{n}{2}\\right) + cn$$\n",
    "\n",
    "**Base case**: $T(1) = c$\n",
    "\n",
    "**Let's trace it for $n = 4$**:\n",
    "```\n",
    "T(4) = 2T(2) + 4c\n",
    "T(2) = 2T(1) + 2c = 2c + 2c = 4c\n",
    "```\n",
    "\n",
    "**Substituting back**:\n",
    "$$\\begin{align}\n",
    "T(4) &= 2T(2) + 4c \\\\\n",
    "&= 2(4c) + 4c \\\\\n",
    "&= 8c + 4c \\\\\n",
    "&= 12c\n",
    "\\end{align}$$\n",
    "\n",
    "**For general $n$, this gives**: $T(n) = O(n \\log n)$\n",
    "\n",
    "## Part 4: Systematic Solution Methods\n",
    "\n",
    "### Method 1: Substitution (Expansion)\n",
    "\n",
    "**Steps**:\n",
    "1. Keep substituting the recurrence into itself\n",
    "2. Look for a pattern\n",
    "3. Express in terms of the base case\n",
    "4. Simplify to get the final answer\n",
    "\n",
    "**Example**: $T(n) = T(n-1) + c$, $T(1) = c$\n",
    "\n",
    "$$\\begin{align}\n",
    "T(n) &= T(n-1) + c \\\\\n",
    "&= (T(n-2) + c) + c \\\\\n",
    "&= ((T(n-3) + c) + c) + c \\\\\n",
    "&= T(n-k) + kc\n",
    "\\end{align}$$\n",
    "\n",
    "**When do we hit base case?** When $n - k = 1$, so $k = n - 1$.\n",
    "\n",
    "$$T(n) = T(1) + (n-1)c = c + (n-1)c = nc = O(n)$$\n",
    "\n",
    "### Method 2: Tree Method (For Divide-and-Conquer)\n",
    "\n",
    "**Example**: $T(n) = 2T(n/2) + cn$\n",
    "\n",
    "**Draw the recursion tree**:\n",
    "```\n",
    "Level 0:           T(n)                    Cost: cn\n",
    "                  /    \\\n",
    "Level 1:      T(n/2)  T(n/2)              Cost: cn/2 + cn/2 = cn\n",
    "             /   \\    /   \\\n",
    "Level 2: T(n/4) T(n/4) T(n/4) T(n/4)     Cost: cn/4 × 4 = cn\n",
    "         ...\n",
    "```\n",
    "\n",
    "**Pattern**:\n",
    "- Each level has cost $cn$\n",
    "- Number of levels = $\\log_2(n)$ (until we reach base case)\n",
    "- **Total cost** = $cn \\times \\log_2(n) = O(n \\log n)$\n",
    "\n",
    "### Method 3: Master Theorem (Complete Explanation)\n",
    "\n",
    "The Master Theorem is a powerful tool for solving divide-and-conquer recurrences, but it requires understanding the intuition behind it.\n",
    "\n",
    "#### What Problems Does Master Theorem Solve?\n",
    "\n",
    "**Form**: $T(n) = aT(n/b) + f(n)$ where:\n",
    "- $a \\geq 1$ = number of subproblems\n",
    "- $b > 1$ = factor by which problem size shrinks\n",
    "- $f(n)$ = cost of dividing and combining\n",
    "\n",
    "#### Building Intuition: The Tree Perspective\n",
    "\n",
    "When we have $T(n) = aT(n/b) + f(n)$, we can draw the recursion tree:\n",
    "\n",
    "```\n",
    "Level 0:           f(n)                    [1 node, each costs f(n)]\n",
    "                  /  |  \\\n",
    "Level 1:      f(n/b) f(n/b) f(n/b)        [a nodes, each costs f(n/b)]\n",
    "             /||\\   /||\\    /||\\\n",
    "Level 2:   f(n/b²) nodes...               [a² nodes, each costs f(n/b²)]\n",
    "           ...\n",
    "Level k:                                  [aᵏ nodes, each costs f(n/bᵏ)]\n",
    "```\n",
    "\n",
    "**Key questions**:\n",
    "1. How many levels are there? $\\log_b(n)$ levels\n",
    "2. How many nodes at level $i$? $a^i$ nodes\n",
    "3. What's the cost at level $i$? $a^i \\cdot f(n/b^i)$\n",
    "4. What's the total cost? Sum over all levels\n",
    "\n",
    "#### The Critical Value: $n^{\\log_b a}$\n",
    "\n",
    "**Why is $n^{\\log_b a}$ important?**\n",
    "\n",
    "At the deepest level (level $\\log_b n$), we have:\n",
    "- Number of nodes = $a^{\\log_b n}$\n",
    "- But $a^{\\log_b n} = (b^{\\log_b a})^{\\log_b n} = b^{\\log_b a \\cdot \\log_b n} = (b^{\\log_b n})^{\\log_b a} = n^{\\log_b a}$\n",
    "\n",
    "So we have $n^{\\log_b a}$ leaves, each with cost $T(1) = O(1)$.\n",
    "\n",
    "**Leaf level cost** = $n^{\\log_b a} \\cdot O(1) = O(n^{\\log_b a})$\n",
    "\n",
    "#### The Three Cases Explained\n",
    "\n",
    "The Master Theorem compares $f(n)$ with $n^{\\log_b a}$ to see which dominates:\n",
    "\n",
    "##### Case 1: Tree is Bottom-Heavy\n",
    "\n",
    "**Condition**: $f(n) = O(n^{\\log_b a - \\epsilon})$ for some $\\epsilon > 0$\n",
    "\n",
    "**Translation**: $f(n)$ grows slower than $n^{\\log_b a}$\n",
    "\n",
    "**Intuition**: The leaves dominate the total cost\n",
    "\n",
    "**Result**: $T(n) = O(n^{\\log_b a})$\n",
    "\n",
    "**Example**: $T(n) = 4T(n/2) + n$\n",
    "- $a = 4$, $b = 2$, so $n^{\\log_b a} = n^{\\log_2 4} = n^2$\n",
    "- $f(n) = n = O(n^{2-1}) = O(n^{2-\\epsilon})$ with $\\epsilon = 1$\n",
    "- Case 1 applies: $T(n) = O(n^2)$\n",
    "\n",
    "**Tree visualization**:\n",
    "```\n",
    "Level 0:      n          [Cost: n]\n",
    "            /   \\\n",
    "Level 1:   n/2  n/2      [Cost: n/2 + n/2 = n]\n",
    "          / |   | \\\n",
    "Level 2: n/4 n/4 n/4 n/4 [Cost: 4 × n/4 = n]\n",
    "         ...\n",
    "Leaves:  (n² leaves)     [Cost: n² × O(1) = n²]  ← DOMINATES\n",
    "```\n",
    "\n",
    "##### Case 2: Tree is Balanced\n",
    "\n",
    "**Condition**: $f(n) = \\Theta(n^{\\log_b a})$\n",
    "\n",
    "**Translation**: $f(n)$ grows at the same rate as $n^{\\log_b a}$\n",
    "\n",
    "**Intuition**: All levels contribute equally\n",
    "\n",
    "**Result**: $T(n) = O(n^{\\log_b a} \\log n)$\n",
    "\n",
    "**Example**: $T(n) = 2T(n/2) + n$ (merge sort)\n",
    "- $a = 2$, $b = 2$, so $n^{\\log_b a} = n^{\\log_2 2} = n^1 = n$\n",
    "- $f(n) = n = \\Theta(n^1) = \\Theta(n^{\\log_b a})$\n",
    "- Case 2 applies: $T(n) = O(n \\log n)$\n",
    "\n",
    "**Tree visualization**:\n",
    "```\n",
    "Level 0:      n          [Cost: n]\n",
    "            /   \\\n",
    "Level 1:   n/2  n/2      [Cost: n]\n",
    "          / |   | \\\n",
    "Level 2: n/4 n/4 n/4 n/4 [Cost: n]\n",
    "         ...\n",
    "All levels have cost n, and there are log n levels\n",
    "Total: n × log n\n",
    "```\n",
    "\n",
    "##### Case 3: Tree is Top-Heavy  \n",
    "**Condition**: $f(n) = \\Omega(n^{\\log_b a + \\epsilon})$ for some $\\epsilon > 0$, AND the regularity condition holds\n",
    "\n",
    "**Translation**: $f(n)$ grows faster than $n^{\\log_b a}$\n",
    "\n",
    "**Intuition**: The root dominates the total cost\n",
    "\n",
    "**Result**: $T(n) = O(f(n))$\n",
    "\n",
    "**Regularity condition**: $af(n/b) \\leq cf(n)$ for some $c < 1$ and sufficiently large $n$\n",
    "\n",
    "**Example**: $T(n) = 2T(n/2) + n^2$\n",
    "- $a = 2$, $b = 2$, so $n^{\\log_b a} = n^1 = n$\n",
    "- $f(n) = n^2 = \\Omega(n^{1+1}) = \\Omega(n^{\\log_b a + \\epsilon})$ with $\\epsilon = 1$\n",
    "- Check regularity: $af(n/b) = 2(n/2)^2 = 2n^2/4 = n^2/2 \\leq cn^2$ with $c = 1/2 < 1$ ✓\n",
    "- Case 3 applies: $T(n) = O(n^2)$\n",
    "\n",
    "**Tree visualization**:\n",
    "```\n",
    "Level 0:      n²         [Cost: n²]  ← DOMINATES\n",
    "            /   \\\n",
    "Level 1:  (n/2)² (n/2)²  [Cost: 2 × n²/4 = n²/2]\n",
    "          / |     | \\\n",
    "Level 2: 4 × (n/4)²      [Cost: 4 × n²/16 = n²/4]\n",
    "         ...\n",
    "Each level is half the cost of the previous level\n",
    "```\n",
    "\n",
    "#### Step-by-Step Application Process\n",
    "\n",
    "**Given**: $T(n) = aT(n/b) + f(n)$\n",
    "\n",
    "**Step 1**: Identify $a$, $b$, and $f(n)$\n",
    "**Step 2**: Calculate $n^{\\log_b a}$\n",
    "**Step 3**: Compare $f(n)$ with $n^{\\log_b a}$:\n",
    "- Is $f(n)$ polynomially smaller? → Case 1\n",
    "- Is $f(n)$ the same order? → Case 2  \n",
    "- Is $f(n)$ polynomially larger? → Check regularity → Case 3\n",
    "**Step 4**: Apply the appropriate case formula\n",
    "\n",
    "#### Common Examples Worked Out\n",
    "\n",
    "**Example 1**: $T(n) = 3T(n/4) + n \\log n$\n",
    "- $a = 3$, $b = 4$, $f(n) = n \\log n$\n",
    "- $n^{\\log_b a} = n^{\\log_4 3} = n^{0.79...}$\n",
    "- Since $n \\log n$ grows faster than $n^{0.79}$, this looks like Case 3\n",
    "- Check regularity: $3f(n/4) = 3 \\cdot \\frac{n}{4} \\log(\\frac{n}{4}) = \\frac{3n}{4}(\\log n - \\log 4)$\n",
    "- For large $n$: $\\frac{3n}{4}(\\log n - \\log 4) \\leq \\frac{3n \\log n}{4} = \\frac{3}{4} \\cdot f(n)$ with $c = 3/4 < 1$ ✓\n",
    "- **Result**: $T(n) = O(n \\log n)$\n",
    "\n",
    "**Example 2**: $T(n) = 9T(n/3) + n^2$\n",
    "- $a = 9$, $b = 3$, $f(n) = n^2$\n",
    "- $n^{\\log_b a} = n^{\\log_3 9} = n^2$\n",
    "- Since $f(n) = n^2 = \\Theta(n^2)$, this is Case 2\n",
    "- **Result**: $T(n) = O(n^2 \\log n)$\n",
    "\n",
    "#### When Master Theorem Doesn't Apply\n",
    "\n",
    "**Gap cases**: When $f(n)$ is between Case 1 and Case 2, or between Case 2 and Case 3.\n",
    "\n",
    "**Example**: $T(n) = 2T(n/2) + \\frac{n}{\\log n}$\n",
    "- $a = 2$, $b = 2$, $n^{\\log_b a} = n$\n",
    "- $f(n) = \\frac{n}{\\log n}$ is slower than $n$ but not polynomially slower\n",
    "- Master Theorem doesn't apply - need other methods\n",
    "\n",
    "**Wrong form**: Recurrences that don't fit $T(n) = aT(n/b) + f(n)$\n",
    "\n",
    "**Examples where it doesn't work**:\n",
    "- $T(n) = T(n-1) + n$ (not divide-and-conquer)\n",
    "- $T(n) = T(n/2) + T(n/3) + n$ (different subproblem sizes)\n",
    "- $T(n) = 2T(n/2 + 1) + n$ (subproblem size isn't exactly $n/b$)\n",
    "\n",
    "## Part 5: Worked Examples Step-by-Step\n",
    "\n",
    "### Example A: Linear Reduction\n",
    "\n",
    "**Recurrence**: $T(n) = T(n-1) + 5$, $T(1) = 3$\n",
    "\n",
    "**Step 1 - Substitution**:\n",
    "$$\\begin{align}\n",
    "T(n) &= T(n-1) + 5 \\\\\n",
    "&= (T(n-2) + 5) + 5 \\\\\n",
    "&= ((T(n-3) + 5) + 5) + 5 \\\\\n",
    "&= T(n-k) + 5k\n",
    "\\end{align}$$\n",
    "\n",
    "**Step 2 - Find base case**: $n - k = 1 \\Rightarrow k = n - 1$\n",
    "\n",
    "**Step 3 - Substitute**: $T(n) = T(1) + 5(n-1) = 3 + 5n - 5 = 5n - 2$\n",
    "\n",
    "**Step 4 - Big-O**: $T(n) = O(n)$\n",
    "\n",
    "### Example B: Binary Division\n",
    "\n",
    "**Recurrence**: $T(n) = T(n/2) + 7$, $T(1) = 2$\n",
    "\n",
    "**Step 1 - Substitution**:\n",
    "$$\\begin{align}\n",
    "T(n) &= T(n/2) + 7 \\\\\n",
    "&= (T(n/4) + 7) + 7 \\\\\n",
    "&= ((T(n/8) + 7) + 7) + 7 \\\\\n",
    "&= T(n/2^k) + 7k\n",
    "\\end{align}$$\n",
    "\n",
    "**Step 2 - Find base case**: $n/2^k = 1 \\Rightarrow 2^k = n \\Rightarrow k = \\log_2(n)$\n",
    "\n",
    "**Step 3 - Substitute**: $T(n) = T(1) + 7\\log_2(n) = 2 + 7\\log_2(n)$\n",
    "\n",
    "**Step 4 - Big-O**: $T(n) = O(\\log n)$\n",
    "\n",
    "### Example C: Double Recursion (Fibonacci-style)\n",
    "\n",
    "**Recurrence**: $T(n) = T(n-1) + T(n-2) + c$, $T(1) = T(2) = c$\n",
    "\n",
    "**This is tricky!** Let's use substitution carefully:\n",
    "\n",
    "**Step 1 - Lower bound**: \n",
    "$T(n) \\geq T(n-2) + T(n-2) = 2T(n-2)$\n",
    "\n",
    "This gives us $T(n) \\geq 2^{n/2} \\cdot c$, so $T(n) = \\Omega(2^{n/2})$\n",
    "\n",
    "**Step 2 - Upper bound**:\n",
    "$T(n) \\leq T(n-1) + T(n-1) = 2T(n-1)$\n",
    "\n",
    "This gives us $T(n) \\leq 2^n \\cdot c$, so $T(n) = O(2^n)$\n",
    "\n",
    "**Result**: $T(n) = O(2^n)$ (exponential - very expensive!)\n",
    "\n",
    "## Part 6: Common Recurrence Patterns\n",
    "\n",
    "### Pattern 1: Linear Reduction\n",
    "**Form**: $T(n) = T(n-1) + f(n)$\n",
    "**Solution**: $T(n) = \\sum_{i=1}^{n} f(i)$\n",
    "**Common case**: If $f(n) = c$, then $T(n) = O(n)$\n",
    "\n",
    "**Examples**:\n",
    "- Linear search: $T(n) = T(n-1) + c \\Rightarrow O(n)$\n",
    "- Insertion sort (worst case): $T(n) = T(n-1) + cn \\Rightarrow O(n^2)$\n",
    "\n",
    "### Pattern 2: Binary Division  \n",
    "**Form**: $T(n) = T(n/2) + f(n)$\n",
    "**Common case**: If $f(n) = c$, then $T(n) = O(\\log n)$\n",
    "\n",
    "**Examples**:\n",
    "- Binary search: $T(n) = T(n/2) + c \\Rightarrow O(\\log n)$\n",
    "- Finding max in tournament: $T(n) = T(n/2) + c \\Rightarrow O(\\log n)$\n",
    "\n",
    "### Pattern 3: Divide and Conquer\n",
    "**Form**: $T(n) = aT(n/b) + f(n)$\n",
    "**Solution**: Use Master Theorem\n",
    "\n",
    "**Examples**:\n",
    "- Merge sort: $T(n) = 2T(n/2) + cn \\Rightarrow O(n \\log n)$\n",
    "- Quick sort (average): $T(n) = 2T(n/2) + cn \\Rightarrow O(n \\log n)$\n",
    "- Karatsuba multiplication: $T(n) = 3T(n/2) + cn \\Rightarrow O(n^{\\log_2 3}) = O(n^{1.58})$\n",
    "\n",
    "### Pattern 4: Multiple Branches\n",
    "**Form**: $T(n) = T(n-1) + T(n-2) + ...$\n",
    "**Solution**: Usually exponential\n",
    "\n",
    "**Examples**:\n",
    "- Naive Fibonacci: $T(n) = T(n-1) + T(n-2) + c \\Rightarrow O(2^n)$\n",
    "- Tower of Hanoi: $T(n) = 2T(n-1) + c \\Rightarrow O(2^n)$\n",
    "\n",
    "## Part 7: Practice Problems with Solutions\n",
    "\n",
    "### Problem 1: Mystery Algorithm A\n",
    "**Recurrence**: $T(n) = T(n-2) + 3$, $T(1) = T(2) = 5$\n",
    "\n",
    "**Solution**:\n",
    "- For even $n$: $T(n) = T(n-2) + 3 = T(n-4) + 6 = ... = T(2) + 3(n/2 - 1) = 5 + 3n/2 - 3 = 3n/2 + 2$\n",
    "- For odd $n$: $T(n) = T(n-2) + 3 = T(n-4) + 6 = ... = T(1) + 3((n-1)/2) = 5 + 3(n-1)/2$\n",
    "\n",
    "**Result**: $T(n) = O(n)$\n",
    "\n",
    "### Problem 2: Mystery Algorithm B  \n",
    "**Recurrence**: $T(n) = 3T(n/3) + 2n$, $T(1) = 1$\n",
    "\n",
    "**Using Master Theorem**:\n",
    "- $a = 3$, $b = 3$, $f(n) = 2n$\n",
    "- $n^{\\log_b a} = n^{\\log_3 3} = n^1 = n$\n",
    "- Since $f(n) = 2n = O(n)$, we're in Case 2\n",
    "- **Result**: $T(n) = O(n \\log n)$\n",
    "\n",
    "### Problem 3: Mystery Algorithm C\n",
    "**Recurrence**: $T(n) = T(n/4) + T(3n/4) + n$, $T(1) = 1$\n",
    "\n",
    "**Using tree method**:\n",
    "```\n",
    "Level 0:              n                     Cost: n\n",
    "                   /     \\\n",
    "Level 1:         n/4     3n/4               Cost: n/4 + 3n/4 = n  \n",
    "               /   \\     /    \\\n",
    "Level 2:    n/16  3n/16 3n/16 9n/16        Cost: n/16 + 3n/16 + 3n/16 + 9n/16 = n\n",
    "```\n",
    "\n",
    "**Pattern**: Each level costs $n$, and we have $O(\\log n)$ levels.\n",
    "**Result**: $T(n) = O(n \\log n)$\n",
    "\n",
    "## Part 8: Common Mistakes and How to Avoid Them\n",
    "\n",
    "### Mistake 1: Forgetting Base Cases\n",
    "**Wrong**: $T(n) = T(n-1) + c$ (what happens when $n = 0$?)\n",
    "**Right**: $T(n) = T(n-1) + c$, $T(1) = c$\n",
    "\n",
    "### Mistake 2: Incorrect Substitution\n",
    "**Wrong**: $T(n) = T(n/2) + n$, then claiming $T(n) = nT(1) = O(n)$\n",
    "**Right**: Must account for how many times we divide\n",
    "\n",
    "### Mistake 3: Misapplying Master Theorem\n",
    "**Wrong**: Using $T(n) = T(n-1) + n$ with Master Theorem\n",
    "**Right**: Master Theorem only applies to $T(n) = aT(n/b) + f(n)$ form\n",
    "\n",
    "### Mistake 4: Ignoring Non-Dominant Terms\n",
    "**Example**: $T(n) = T(n/2) + \\log n + 100$\n",
    "**Common error**: Treating the $+100$ as significant\n",
    "**Truth**: The $\\log n$ term dominates for large $n$, constant is negligible\n",
    "\n",
    "## Part 9: Why Recurrence Relations Matter\n",
    "\n",
    "### Algorithm Analysis\n",
    "Recurrence relations are the mathematical foundation for analyzing:\n",
    "- **Recursive algorithms**: Direct translation of code to math\n",
    "- **Divide-and-conquer**: Breaking problems into smaller pieces  \n",
    "- **Dynamic programming**: Understanding overlapping subproblems\n",
    "- **Tree algorithms**: Height and traversal analysis\n",
    "\n",
    "### Practical Applications\n",
    "Understanding recurrences helps you:\n",
    "1. **Predict performance**: Will your algorithm scale?\n",
    "2. **Compare approaches**: Which recursive strategy is better?\n",
    "3. **Optimize code**: Identify bottlenecks in recursive solutions\n",
    "4. **Design algorithms**: Choose the right recursive structure\n",
    "\n",
    "### Real-World Examples\n",
    "- **Database indexing**: B-tree operations follow $T(n) = T(n/m) + O(\\log m)$\n",
    "- **Graphics rendering**: Quad-tree operations are $T(n) = 4T(n/4) + O(1)$\n",
    "- **Network routing**: Shortest path algorithms often recursive\n",
    "- **Machine learning**: Many ML algorithms have recursive structure\n",
    "\n",
    "## Part 10: Summary and Key Takeaways\n",
    "\n",
    "### The Big Picture\n",
    "1. **Recurrence relations** express how algorithms break down problems\n",
    "2. **Solution methods** include substitution, tree method, and Master Theorem\n",
    "3. **Common patterns** emerge based on how problem size reduces\n",
    "4. **Big-O analysis** follows naturally from recurrence solutions\n",
    "\n",
    "### Pattern Recognition Guide\n",
    "| Problem Reduction | Typical Recurrence | Time Complexity |\n",
    "|-------------------|-------------------|-----------------|\n",
    "| Subtract constant | $T(n) = T(n-1) + f(n)$ | $O(\\sum f(i))$ |\n",
    "| Divide by constant | $T(n) = T(n/c) + f(n)$ | $O(f(n) \\log n)$ |\n",
    "| Split into parts | $T(n) = aT(n/b) + f(n)$ | Use Master Theorem |\n",
    "| Multiple recursion | $T(n) = T(n-1) + T(n-2)$ | Often exponential |\n",
    "\n",
    "### Master the Fundamentals\n",
    "- **Start simple**: Linear and logarithmic patterns first\n",
    "- **Practice substitution**: Most reliable method for beginners  \n",
    "- **Draw trees**: Visual approach helps with divide-and-conquer\n",
    "- **Check your work**: Verify with small examples\n",
    "\n",
    "**Remember**: Recurrence relations are the bridge between recursive thinking and mathematical analysis - master them to understand algorithm complexity at a deep level!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3730285",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd85def",
   "metadata": {},
   "source": [
    "# Linear Search Complexity\n",
    "\n",
    "## Part 1: Understanding the Algorithm First\n",
    "\n",
    "### What is Linear Search?\n",
    "\n",
    "Linear search is the most intuitive search algorithm - it's exactly how you'd naturally look for something:\n",
    "\n",
    "1. Start at the beginning\n",
    "2. Check each item one by one\n",
    "3. If you find what you're looking for, stop\n",
    "4. If you reach the end without finding it, it's not there\n",
    "\n",
    "Think of it like looking for your keys by checking every pocket, drawer, and surface in order until you find them (or run out of places to look).\n",
    "\n",
    "### Visual Example: Finding 7 in [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "\n",
    "```\n",
    "Step 1: Check position 0: 3 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "         ↑\n",
    "\n",
    "Step 2: Check position 1: 1 ≠ 7, continue  \n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "           ↑\n",
    "\n",
    "Step 3: Check position 2: 4 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "             ↑\n",
    "\n",
    "Step 4: Check position 3: 1 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "               ↑\n",
    "\n",
    "Step 5: Check position 4: 5 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "                 ↑\n",
    "\n",
    "Step 6: Check position 5: 9 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "                   ↑\n",
    "\n",
    "Step 7: Check position 6: 2 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "                     ↑\n",
    "\n",
    "Step 8: Check position 7: 6 ≠ 7, continue\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "                       ↑\n",
    "\n",
    "Step 9: Check position 8: 7 = 7, Found it! ✓\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "                         ↑\n",
    "```\n",
    "\n",
    "**Result**: Found 7 at position 8 after 9 comparisons.\n",
    "\n",
    "## Part 2: Analyzing Different Scenarios\n",
    "\n",
    "### Best Case: Element is at the Beginning\n",
    "\n",
    "Looking for 3 in [3,1,4,1,5,9,2,6,7,3,5,8]:\n",
    "```\n",
    "Step 1: Check position 0: 3 = 3, Found it! ✓\n",
    "        [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "         ↑\n",
    "```\n",
    "**Comparisons needed**: 1\n",
    "\n",
    "### Worst Case: Element is at the End (or Not There)\n",
    "\n",
    "#### Element at the end - Looking for 8:\n",
    "```\n",
    "Step 1-11: Check positions 0-10: all ≠ 8\n",
    "Step 12: Check position 11: 8 = 8, Found it! ✓\n",
    "         [3,1,4,1,5,9,2,6,7,3,5,8]\n",
    "                                 ↑\n",
    "```\n",
    "**Comparisons needed**: 12 (the full array size)\n",
    "\n",
    "#### Element not in array - Looking for 42:\n",
    "```\n",
    "Step 1-12: Check all positions 0-11: all ≠ 42\n",
    "Result: Not found\n",
    "```\n",
    "**Comparisons needed**: 12 (still the full array size)\n",
    "\n",
    "### Average Case: Element Could Be Anywhere\n",
    "\n",
    "If the element we're looking for is equally likely to be at any position:\n",
    "\n",
    "**Positions**: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11  \n",
    "**Comparisons needed**: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n",
    "\n",
    "**Average comparisons** = $\\frac{1 + 2 + 3 + ... + n}{n} = \\frac{n(n+1)/2}{n} = \\frac{n+1}{2}$\n",
    "\n",
    "For our 12-element array: $\\frac{12+1}{2} = 6.5$ comparisons on average.\n",
    "\n",
    "## Part 3: Building the Pattern - Different Array Sizes\n",
    "\n",
    "### Let's Count Steps for Various Sizes\n",
    "\n",
    "#### Size 1: [5]\n",
    "- **Best case**: 1 comparison (element is there)\n",
    "- **Worst case**: 1 comparison (element not there)  \n",
    "- **Average case**: 1 comparison\n",
    "\n",
    "#### Size 3: [2,7,1]\n",
    "- **Best case**: 1 comparison (first element)\n",
    "- **Worst case**: 3 comparisons (last element or not found)\n",
    "- **Average case**: $\\frac{1+2+3}{3} = 2$ comparisons\n",
    "\n",
    "#### Size 5: [9,3,1,8,4]\n",
    "- **Best case**: 1 comparison\n",
    "- **Worst case**: 5 comparisons  \n",
    "- **Average case**: $\\frac{1+2+3+4+5}{5} = 3$ comparisons\n",
    "\n",
    "### The Pattern Emerges\n",
    "\n",
    "| Array Size (n) | Best Case | Worst Case | Average Case |\n",
    "|----------------|-----------|------------|--------------|\n",
    "| 1              | 1         | 1          | 1.0          |\n",
    "| 2              | 1         | 2          | 1.5          |\n",
    "| 3              | 1         | 3          | 2.0          |\n",
    "| 5              | 1         | 5          | 3.0          |\n",
    "| 10             | 1         | 10         | 5.5          |\n",
    "| 100            | 1         | 100        | 50.5         |\n",
    "| 1000           | 1         | 1000       | 500.5        |\n",
    "\n",
    "**Key Observation**: The worst case grows **linearly** with array size!\n",
    "\n",
    "## Part 4: Mathematical Analysis\n",
    "\n",
    "### Setting Up the Analysis\n",
    "\n",
    "Let $T(n)$ = time to search in an array of size $n$\n",
    "\n",
    "**What happens in linear search?**\n",
    "- In the **best case**: Check first element, done → $T(n) = O(1)$\n",
    "- In the **worst case**: Check all $n$ elements → $T(n) = O(n)$  \n",
    "- In the **average case**: Check about $n/2$ elements → $T(n) = O(n)$\n",
    "\n",
    "### Detailed Worst-Case Analysis\n",
    "\n",
    "**Step-by-step for worst case**:\n",
    "1. Check element at position 0: 1 comparison\n",
    "2. Check element at position 1: 1 comparison  \n",
    "3. Check element at position 2: 1 comparison\n",
    "4. ...\n",
    "5. Check element at position $n-1$: 1 comparison\n",
    "\n",
    "**Total comparisons** = $1 + 1 + 1 + ... + 1$ ($n$ times) = $n$\n",
    "\n",
    "Therefore: $T(n) = n = O(n)$\n",
    "\n",
    "### Average-Case Analysis (More Detailed)\n",
    "\n",
    "**Assumption**: The target element is equally likely to be at any position, or not in the array at all.\n",
    "\n",
    "**Scenario 1**: Element is in the array (probability = $p$)\n",
    "- Could be at position 1, 2, 3, ..., $n$ with equal probability $\\frac{p}{n}$\n",
    "- Expected comparisons = $\\frac{p}{n}(1 + 2 + 3 + ... + n) = \\frac{p}{n} \\cdot \\frac{n(n+1)}{2} = \\frac{p(n+1)}{2}$\n",
    "\n",
    "**Scenario 2**: Element is not in array (probability = $1-p$)  \n",
    "- Must check all $n$ elements\n",
    "- Expected comparisons = $(1-p) \\cdot n$\n",
    "\n",
    "**Total expected comparisons**:\n",
    "$$E[T(n)] = \\frac{p(n+1)}{2} + (1-p)n = \\frac{p(n+1) + 2(1-p)n}{2} = \\frac{pn + p + 2n - 2pn}{2} = \\frac{2n - pn + p}{2}$$\n",
    "\n",
    "**Special case** (element is definitely in array, $p = 1$):\n",
    "$$E[T(n)] = \\frac{n+1}{2} = O(n)$$\n",
    "\n",
    "**Common case** (element may or may not be there, $p = 0.5$):\n",
    "$$E[T(n)] = \\frac{2n - 0.5n + 0.5}{2} = \\frac{1.5n + 0.5}{2} = 0.75n + 0.25 = O(n)$$\n",
    "\n",
    "## Part 5: Concrete Walkthrough Examples\n",
    "\n",
    "### Example 1: Searching for \"Emma\" in a Class List\n",
    "\n",
    "Names: `[\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Emma\", \"Frank\", \"Grace\"]`\n",
    "\n",
    "```\n",
    "Step 1: Compare \"Emma\" with \"Alice\" → Not equal, continue\n",
    "Step 2: Compare \"Emma\" with \"Bob\" → Not equal, continue  \n",
    "Step 3: Compare \"Emma\" with \"Charlie\" → Not equal, continue\n",
    "Step 4: Compare \"Emma\" with \"David\" → Not equal, continue\n",
    "Step 5: Compare \"Emma\" with \"Emma\" → Equal! Found at position 4\n",
    "```\n",
    "\n",
    "**Result**: 5 comparisons for array of size 7.\n",
    "\n",
    "### Example 2: Searching for \"Zoe\" (Not in List)\n",
    "\n",
    "```\n",
    "Step 1: Compare \"Zoe\" with \"Alice\" → Not equal, continue\n",
    "Step 2: Compare \"Zoe\" with \"Bob\" → Not equal, continue\n",
    "Step 3: Compare \"Zoe\" with \"Charlie\" → Not equal, continue  \n",
    "Step 4: Compare \"Zoe\" with \"David\" → Not equal, continue\n",
    "Step 5: Compare \"Zoe\" with \"Emma\" → Not equal, continue\n",
    "Step 6: Compare \"Zoe\" with \"Frank\" → Not equal, continue\n",
    "Step 7: Compare \"Zoe\" with \"Grace\" → Not equal, continue\n",
    "End of array reached → Not found\n",
    "```\n",
    "\n",
    "**Result**: 7 comparisons for array of size 7 (checked every element).\n",
    "\n",
    "### Example 3: Finding Multiple Occurrences\n",
    "\n",
    "Looking for all occurrences of 3 in `[1,3,7,3,9,3,2]`:\n",
    "\n",
    "```\n",
    "Step 1: 1 ≠ 3, continue\n",
    "Step 2: 3 = 3, found at position 1, continue searching\n",
    "Step 3: 7 ≠ 3, continue  \n",
    "Step 4: 3 = 3, found at position 3, continue searching\n",
    "Step 5: 9 ≠ 3, continue\n",
    "Step 6: 3 = 3, found at position 5, continue searching\n",
    "Step 7: 2 ≠ 3, continue\n",
    "End reached\n",
    "```\n",
    "\n",
    "**Result**: Still needed 7 comparisons to find all occurrences, but found 3 matches.\n",
    "\n",
    "## Part 6: Why Linear Growth Matters\n",
    "\n",
    "### The Impact of Size\n",
    "\n",
    "Here's how linear search performance degrades:\n",
    "\n",
    "| Array Size | Best Case | Average Case | Worst Case |\n",
    "|------------|-----------|--------------|------------|\n",
    "| 10         | 1         | 5.5          | 10         |\n",
    "| 100        | 1         | 50.5         | 100        |\n",
    "| 1,000      | 1         | 500.5        | 1,000      |\n",
    "| 10,000     | 1         | 5,000.5      | 10,000     |\n",
    "| 100,000    | 1         | 50,000.5     | 100,000    |\n",
    "| 1,000,000  | 1         | 500,000.5    | 1,000,000  |\n",
    "\n",
    "**Key insight**: When you double the array size, you double the worst-case time!\n",
    "\n",
    "### Real-World Implications\n",
    "\n",
    "**Example**: Searching through a phone book\n",
    "- 1,000 names: Up to 1,000 comparisons  \n",
    "- 10,000 names: Up to 10,000 comparisons\n",
    "- 100,000 names: Up to 100,000 comparisons\n",
    "\n",
    "This is why we need more efficient algorithms for large datasets!\n",
    "\n",
    "### The \"Doubling\" Problem\n",
    "\n",
    "Unlike binary search's logarithmic growth, linear search has a **linear growth problem**:\n",
    "\n",
    "**Mathematical proof**:\n",
    "- Array of size $n$: $O(n)$ time\n",
    "- Array of size $2n$: $O(2n) = 2 \\cdot O(n)$ time\n",
    "\n",
    "**Doubling the input doubles the time** - this doesn't scale well!\n",
    "\n",
    "## Part 7: Space Complexity Analysis\n",
    "\n",
    "### Iterative Version (Most Common)\n",
    "\n",
    "```python\n",
    "def linear_search(arr, target):\n",
    "    for i in range(len(arr)):      # O(1) space for loop variable\n",
    "        if arr[i] == target:       # O(1) space for comparison\n",
    "            return i               # O(1) space for return\n",
    "    return -1                      # O(1) space\n",
    "```\n",
    "\n",
    "**Space complexity**: $O(1)$ - only uses a constant amount of extra space.\n",
    "\n",
    "### With Index Tracking\n",
    "\n",
    "```python\n",
    "def linear_search_with_tracking(arr, target):\n",
    "    found_indices = []             # O(k) space where k = number of matches\n",
    "    for i in range(len(arr)):      # O(1) space for loop variable  \n",
    "        if arr[i] == target:       # O(1) space for comparison\n",
    "            found_indices.append(i) # Space grows with matches\n",
    "    return found_indices\n",
    "```\n",
    "\n",
    "**Space complexity**: $O(k)$ where $k$ is the number of matches (worst case: $O(n)$ if all elements match).\n",
    "\n",
    "### Recursive Version (Less Common)\n",
    "\n",
    "```python\n",
    "def linear_search_recursive(arr, target, index=0):\n",
    "    if index >= len(arr):          # Base case: not found\n",
    "        return -1\n",
    "    if arr[index] == target:       # Base case: found\n",
    "        return index  \n",
    "    return linear_search_recursive(arr, target, index + 1)  # Recursive call\n",
    "```\n",
    "\n",
    "**Space complexity**: $O(n)$ - each recursive call uses stack space, and we might make $n$ calls in the worst case.\n",
    "\n",
    "**Note**: The recursive version is inefficient for linear search since it doesn't benefit from the recursive structure.\n",
    "\n",
    "## Part 8: When to Use Linear Search\n",
    "\n",
    "### Advantages of Linear Search\n",
    "\n",
    "1. **Simplicity**: Easiest algorithm to understand and implement\n",
    "2. **No preprocessing**: Works on unsorted arrays  \n",
    "3. **Memory efficient**: $O(1)$ space complexity\n",
    "4. **Stable**: Finds first occurrence naturally\n",
    "5. **Works everywhere**: No special requirements for data structure\n",
    "\n",
    "### When Linear Search is Optimal\n",
    "\n",
    "#### Small Arrays (n < 20)\n",
    "For very small arrays, linear search can be faster than more complex algorithms due to:\n",
    "- Lower constant factors\n",
    "- No overhead from complex operations\n",
    "- Better cache locality\n",
    "\n",
    "#### Unsorted Data\n",
    "When data isn't sorted and you need to search infrequently:\n",
    "- Sorting cost: $O(n \\log n)$  \n",
    "- Linear search cost: $O(n)$\n",
    "- If you search less often than you add elements, linear search wins\n",
    "\n",
    "#### Finding All Occurrences\n",
    "When you need all instances of a value:\n",
    "```\n",
    "Linear search: O(n) - must check every element anyway\n",
    "Binary search: O(log n + k) where k = number of occurrences\n",
    "```\n",
    "For finding all occurrences, linear search is often simpler.\n",
    "\n",
    "### When Linear Search is Poor\n",
    "\n",
    "#### Large Datasets\n",
    "- 1 million elements: up to 1 million comparisons\n",
    "- Binary search on same data: at most 20 comparisons\n",
    "- **Performance difference**: 50,000× slower!\n",
    "\n",
    "#### Repeated Searches\n",
    "If you search the same dataset many times:\n",
    "- Sort once: $O(n \\log n)$\n",
    "- Each binary search: $O(\\log n)$  \n",
    "- Each linear search: $O(n)$\n",
    "- **Break-even point**: After $\\log n$ searches, binary search wins\n",
    "\n",
    "## Part 9: Comparison with Other Search Algorithms\n",
    "\n",
    "### Linear Search vs Binary Search\n",
    "\n",
    "| Aspect           | Linear Search | Binary Search |\n",
    "|------------------|---------------|---------------|\n",
    "| **Prerequisite** | None          | Sorted array  |\n",
    "| **Time (Best)**  | $O(1)$        | $O(1)$        |\n",
    "| **Time (Average)**| $O(n)$       | $O(\\log n)$   |\n",
    "| **Time (Worst)** | $O(n)$        | $O(\\log n)$   |\n",
    "| **Space**        | $O(1)$        | $O(1)$ iterative |\n",
    "| **Implementation** | Very simple  | Moderate      |\n",
    "| **Data structure** | Any array    | Sorted array  |\n",
    "\n",
    "### Performance Comparison Table\n",
    "\n",
    "| Array Size | Linear (Worst) | Binary (Worst) | Speedup |\n",
    "|------------|----------------|----------------|---------|\n",
    "| 10         | 10             | 4              | 2.5×    |\n",
    "| 100        | 100            | 7              | 14×     |\n",
    "| 1,000      | 1,000          | 10             | 100×    |\n",
    "| 10,000     | 10,000         | 14             | 714×    |\n",
    "| 100,000    | 100,000        | 17             | 5,882×  |\n",
    "| 1,000,000  | 1,000,000      | 20             | 50,000× |\n",
    "\n",
    "## Part 10: Summary and Key Takeaways\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "1. **Time Complexity**: \n",
    "   - Best case: $O(1)$ - element is first\n",
    "   - Average case: $O(n)$ - element is in middle  \n",
    "   - Worst case: $O(n)$ - element is last or missing\n",
    "\n",
    "2. **Space Complexity**: $O(1)$ - constant extra space\n",
    "\n",
    "3. **Key Characteristic**: **Linear growth** - doubling input size doubles time\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "#### Understanding Algorithm Trade-offs\n",
    "Linear search teaches us about:\n",
    "- **Simplicity vs Efficiency**: Sometimes the simplest solution isn't the most efficient\n",
    "- **Preprocessing costs**: Sorting enables faster searches but has upfront cost\n",
    "- **Problem constraints**: Unsorted data limits our algorithmic choices\n",
    "\n",
    "#### When Simple is Better\n",
    "Linear search reminds us that:\n",
    "- Complex isn't always better for small problems\n",
    "- Implementation simplicity has value\n",
    "- Understanding worst-case behavior is crucial\n",
    "\n",
    "### The Mathematical Beauty\n",
    "\n",
    "The recurrence relation for linear search is trivial: $T(n) = T(n-1) + O(1)$ with solution $T(n) = O(n)$, but this simplicity teaches us:\n",
    "\n",
    "- How algorithm analysis works on basic examples\n",
    "- The importance of input characteristics (sorted vs unsorted)  \n",
    "- Why we need more sophisticated approaches for large-scale problems\n",
    "\n",
    "**Remember**: Linear search is the foundation - understanding its limitations motivates learning more efficient algorithms like binary search, hash tables, and tree-based searches!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff41370d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5df6e6",
   "metadata": {},
   "source": [
    "# Binary Search Complexity\n",
    "\n",
    "## Part 1: Understanding the Algorithm First\n",
    "\n",
    "### What is Binary Search?\n",
    "\n",
    "Binary search is like playing a number guessing game where someone thinks of a number between 1 and 100, and you have to guess it. The smart strategy is:\n",
    "\n",
    "1. Guess 50 (the middle)\n",
    "2. If they say \"higher,\" guess 75 (middle of 51-100)  \n",
    "3. If they say \"lower,\" guess 25 (middle of 1-49)\n",
    "4. Keep splitting the remaining range in half\n",
    "\n",
    "**Key insight**: Each guess eliminates half of the remaining possibilities!\n",
    "\n",
    "### Visual Example: Finding 7 in [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "```\n",
    "Step 0: [1,2,3,4,5,6,7,8,9,10,11,12]  (size = 12)\n",
    "         ↑           ↑              ↑\n",
    "        low        mid=6           high\n",
    "        Compare 7 vs 6: 7 > 6, so search right half\n",
    "\n",
    "Step 1: [7,8,9,10,11,12]  (size = 6)\n",
    "         ↑   ↑        ↑\n",
    "        low mid=9    high  \n",
    "        Compare 7 vs 9: 7 < 9, so search left half\n",
    "\n",
    "Step 2: [7,8]  (size = 2)\n",
    "         ↑ ↑\n",
    "        low,mid & high\n",
    "        Compare 7 vs 7: Found it! ✓\n",
    "```\n",
    "\n",
    "**Pattern**: 12 → 6 → 2 → 1 (found)\n",
    "\n",
    "## Part 2: Counting Steps - Building the Pattern\n",
    "\n",
    "### Let's Try Different Array Sizes\n",
    "\n",
    "#### Size 4: [1,2,3,4]\n",
    "```\n",
    "Step 0: [1,2,3,4] → compare with middle element (2 or 3)\n",
    "Step 1: [3,4] or [1,2] → compare with remaining middle  \n",
    "Step 2: [4] or [1] → found (or not found)\n",
    "```\n",
    "**Maximum steps**: 3\n",
    "\n",
    "#### Size 8: [1,2,3,4,5,6,7,8]\n",
    "```\n",
    "Step 0: [1,2,3,4,5,6,7,8] (size 8)\n",
    "Step 1: [5,6,7,8] or [1,2,3,4] (size 4)  \n",
    "Step 2: [7,8] or [1,2] or [5,6] or [3,4] (size 2)\n",
    "Step 3: [8] or [1] or [6] or [3] or similar (size 1)\n",
    "```\n",
    "**Maximum steps**: 4\n",
    "\n",
    "#### Size 16: Maximum 5 steps\n",
    "#### Size 32: Maximum 6 steps\n",
    "\n",
    "### The Pattern Emerges\n",
    "\n",
    "| Array Size | Max Steps | What's the Pattern? |\n",
    "|------------|-----------|---------------------|\n",
    "| 1          | 1         | $2^0 = 1$          |\n",
    "| 2          | 2         | $2^1 = 2$          |  \n",
    "| 4          | 3         | $2^2 = 4$          |\n",
    "| 8          | 4         | $2^3 = 8$          |\n",
    "| 16         | 5         | $2^4 = 16$         |\n",
    "| 32         | 6         | $2^5 = 32$         |\n",
    "\n",
    "**Aha moment**: If the array size is $2^k$, then we need at most $k+1$ steps!\n",
    "\n",
    "## Part 3: The Mathematical Connection\n",
    "\n",
    "### Why Does This Pattern Work?\n",
    "\n",
    "At each step, we cut the problem size in half:\n",
    "\n",
    "$$\\text{Original size} = n$$\n",
    "\n",
    "$$\\text{After 1 step} = \\frac{n}{2}$$\n",
    "\n",
    "$$\\text{After 2 steps} = \\frac{n}{4} = \\frac{n}{2^2}$$\n",
    "$$\\text{After 3 steps} = \\frac{n}{8} = \\frac{n}{2^3}$$\n",
    "$$\\text{After k steps} = \\frac{n}{2^k}$$\n",
    "\n",
    "### When Do We Stop?\n",
    "\n",
    "We stop when we have 1 element left (or 0 if not found):\n",
    "\n",
    "$$\\frac{n}{2^k} = 1$$\n",
    "\n",
    "Solving for $k$:\n",
    "$$n = 2^k$$\n",
    "$$k = \\log_2(n)$$\n",
    "\n",
    "### What About Non-Powers of 2?\n",
    "\n",
    "For arrays that aren't perfect powers of 2, we need the ceiling function:\n",
    "\n",
    "**Maximum steps** = $\\lceil \\log_2(n) \\rceil$\n",
    "\n",
    "#### Examples:\n",
    "- $n = 10$: $\\log_2(10) = 3.32...$, so $\\lceil 3.32 \\rceil = 4$ steps\n",
    "- $n = 100$: $\\log_2(100) = 6.64...$, so $\\lceil 6.64 \\rceil = 7$ steps  \n",
    "- $n = 1000$: $\\log_2(1000) = 9.97...$, so $\\lceil 9.97 \\rceil = 10$ steps\n",
    "\n",
    "## Part 4: Step-by-Step Complexity Analysis\n",
    "\n",
    "### Setting Up the Recurrence\n",
    "\n",
    "Let $T(n)$ = time to search in an array of size $n$\n",
    "\n",
    "**What happens in one step of binary search?**\n",
    "1. Compare target with middle element: $O(1)$ time\n",
    "2. Choose left or right half: $O(1)$ time  \n",
    "3. Search the chosen half of size $\\frac{n}{2}$: $T(\\frac{n}{2})$ time\n",
    "\n",
    "**Recurrence relation:**\n",
    "$$T(n) = T\\left(\\frac{n}{2}\\right) + O(1)$$\n",
    "\n",
    "**Base case:** \n",
    "$$T(1) = O(1) \\text{ (found it or determined it's not there)}$$\n",
    "\n",
    "### Solving the Recurrence Step-by-Step\n",
    "\n",
    "Let's expand $T(n)$ by substitution:\n",
    "\n",
    "$$\\begin{align}\n",
    "T(n) &= T\\left(\\frac{n}{2}\\right) + c \\\\\n",
    "&= T\\left(\\frac{n}{4}\\right) + c + c \\\\  \n",
    "&= T\\left(\\frac{n}{8}\\right) + c + c + c \\\\\n",
    "&= T\\left(\\frac{n}{2^k}\\right) + k \\cdot c\n",
    "\\end{align}$$\n",
    "\n",
    "When do we reach the base case? When $\\frac{n}{2^k} = 1$, so $k = \\log_2(n)$.\n",
    "\n",
    "Substituting back:\n",
    "$$T(n) = T(1) + \\log_2(n) \\cdot c = O(1) + O(\\log n) = O(\\log n)$$\n",
    "\n",
    "## Part 5: Concrete Walkthrough Examples\n",
    "\n",
    "### Example 1: Searching for 23 in array of size 15\n",
    "\n",
    "Array: `[1,3,5,7,9,11,13,15,17,19,21,23,25,27,29]`\n",
    "\n",
    "```\n",
    "Step 1: Array[0..14], middle = 7, value = 15\n",
    "        23 > 15, search right: Array[8..14]\n",
    "        \n",
    "Step 2: Array[8..14], middle = 11, value = 21  \n",
    "        23 > 21, search right: Array[12..14]\n",
    "        \n",
    "Step 3: Array[12..14], middle = 13, value = 25\n",
    "        23 < 25, search left: Array[12..12]\n",
    "        \n",
    "Step 4: Array[12..12], middle = 12, value = 23\n",
    "        Found it! ✓\n",
    "```\n",
    "\n",
    "**Steps taken**: 4  \n",
    "**Theory predicts**: $\\lceil \\log_2(15) \\rceil = \\lceil 3.91 \\rceil = 4$ ✓\n",
    "\n",
    "### Example 2: Why Linear Search is Much Worse\n",
    "\n",
    "Same array, but with linear search for 23:\n",
    "```\n",
    "Check position 0: 1 ≠ 23\n",
    "Check position 1: 3 ≠ 23  \n",
    "Check position 2: 5 ≠ 23\n",
    "...\n",
    "Check position 11: 23 = 23 ✓\n",
    "```\n",
    "\n",
    "**Linear search**: 12 steps  \n",
    "**Binary search**: 4 steps  \n",
    "**Improvement**: 3× better\n",
    "\n",
    "## Part 6: The Power of Logarithmic Growth\n",
    "\n",
    "### Why Logarithms Grow So Slowly\n",
    "\n",
    "Here's the stunning reality of logarithmic growth:\n",
    "\n",
    "| Array Size | Linear Search (worst) | Binary Search (worst) | Ratio |\n",
    "|------------|----------------------|-----------------------|--------|\n",
    "| 10         | 10                   | 4                     | 2.5×   |\n",
    "| 100        | 100                  | 7                     | 14×    |\n",
    "| 1,000      | 1,000                | 10                    | 100×   |\n",
    "| 10,000     | 10,000               | 14                    | 714×   |\n",
    "| 100,000    | 100,000              | 17                    | 5,882× |\n",
    "| 1,000,000  | 1,000,000            | 20                    | 50,000×|\n",
    "\n",
    "### The \"Doubling\" Property\n",
    "\n",
    "**Key insight**: When you double the array size, binary search needs only **one more step**.\n",
    "\n",
    "**Proof**:\n",
    "- Array of size $n$: $\\log_2(n)$ steps\n",
    "- Array of size $2n$: $\\log_2(2n) = \\log_2(2) + \\log_2(n) = 1 + \\log_2(n)$ steps\n",
    "\n",
    "This is why binary search scales incredibly well!\n",
    "\n",
    "## Part 7: Space Complexity Analysis\n",
    "\n",
    "### Iterative Version (Most Common)\n",
    "```python\n",
    "def binary_search_iterative(arr, target):\n",
    "    left, right = 0, len(arr) - 1  # O(1) space\n",
    "    \n",
    "    while left <= right:           # O(1) space per iteration\n",
    "        mid = (left + right) // 2  # O(1) space\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "```\n",
    "\n",
    "**Space complexity**: $O(1)$ - only uses a constant amount of extra variables.\n",
    "\n",
    "### Recursive Version\n",
    "```python  \n",
    "def binary_search_recursive(arr, target, left=0, right=None):\n",
    "    if right is None:\n",
    "        right = len(arr) - 1\n",
    "        \n",
    "    if left > right:\n",
    "        return -1\n",
    "    \n",
    "    mid = (left + right) // 2\n",
    "    if arr[mid] == target:\n",
    "        return mid\n",
    "    elif arr[mid] < target:\n",
    "        return binary_search_recursive(arr, target, mid+1, right)\n",
    "    else:\n",
    "        return binary_search_recursive(arr, target, left, mid-1)\n",
    "```\n",
    "\n",
    "**Space complexity**: $O(\\log n)$ - each recursive call uses stack space, and we make at most $\\log n$ calls.\n",
    "\n",
    "## Part 8: Summary and Key Takeaways\n",
    "\n",
    "### The Big Picture\n",
    "1. **Time Complexity**: $O(\\log n)$ - logarithmic time\n",
    "2. **Space Complexity**: $O(1)$ iterative, $O(\\log n)$ recursive\n",
    "3. **Requirement**: Array must be sorted\n",
    "4. **Strategy**: Eliminate half the possibilities with each comparison\n",
    "\n",
    "### Why This Matters\n",
    "- **Efficiency**: Searching 1 billion elements takes only ~30 comparisons\n",
    "- **Scalability**: Performance barely degrades as data grows\n",
    "- **Fundamental**: Forms the basis for many advanced algorithms\n",
    "\n",
    "### The Mathematical Beauty\n",
    "The recurrence relation $T(n) = T(n/2) + O(1)$ with solution $T(n) = O(\\log n)$ appears throughout computer science - in merge sort analysis, tree height calculations, and many divide-and-conquer algorithms.\n",
    "\n",
    "**Remember**: Binary search turns an exponentially large search problem into a logarithmically small number of operations - that's the power of smart algorithm design!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
